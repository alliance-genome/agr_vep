# VEP annotation pipeline for MOD high throughput variations

- Runs VEP on MOD high throughput variation VCF files
- Splits input files, runs VEP in parallel, then combines the output.
- Uses MOD GFF, FASTA, and (optionally) BAM files to construct translated protein sequences.
- Retrieves SIFT and PolyPhen annotations from databases generated by the VepProteinFunction pipeline.


## Requirements

See the links below for associated dependencies and required databases

- EnsEMBL Hive ([eHive docs](https://ensembl-hive.readthedocs.io/en/version2.5/quickstart/install.html))
- EnsEMBL VEP ([VEP docs](https://m.ensembl.org/info/docs/tools/vep/script/vep_download.html#installer))
- Databases created using the VepProteinFunction pipeline
- bgzip
- tabix

Perl libraries:
- File::Copy
- File::Path
- Data::Dumper
- Digest::MD5


## Installation

- Copy `GenomePos.pm`, `TranscriptName.pm`, `ProtFuncAnnot.pm`, `ProtFuncAnnotHTP.pm`, and `ProtFuncSeq.pm` to the VEP Plugins directory (usually `~/.vep/Plugins`).


## Running the pipeline


The following variables need to be set in the `initialise_pipeline.sh` script:
- `mod` - name of the MOD, eg. WB.
- `fasta` - FASTA file containing genome sequence.
- `gff` - GFF3 file containing genome annotations.
- `bam` - BAM file containing alignments of transcripts against genome, required if GFF3 contains RefSeq transcripts (set to 0 if not required).
- `hive_root_dir` - root directory containing EnsEMBL eHive Perl modules.
- `pipeline_base_dir` - location for files generated by pipeline to be saved.
- `pipeline_host` - MySQL database server for pipeline databases.
- `pipeline_user` - MySQL user.
- `pipeline_port` - MySQL server port.
- `lsf_queue` - name of the LSF queue used for running jobs on the cluster.
- `vep_dir` - VEP installation directory.

The pipeline should be initialised using the `runpipeline.sh` script.  The password for the MySQL databases needs to be specified as the first argument.
- Enter a `screen` or `tmux` session
- Run the pipeline initialisation script - e.g. `./initialise_pipeline.sh mysql_pass`.
- Copy and execute the appropriate line from the output to set the `$EHIVE_URL` environmental variable.
- Run the pipeline - `beekeeper.pl $EHIVE_URL -loop`.


## Pipeline runnable details

### SplitInput.pm

- Splits input VCF file and writes to files with 5-digit suffixes.


### RunVep.pm

- Runs VEP on split files.
- Removes header lines from all output files except first file.
- Uses ProtFuncAnnot.pm VEP plugin to retrieve SIFT and Polyphen results from databases created with the VepProteinFunction pipeline.


### RunPartialVep.pm

- Only runs if RunVep.pm failed for a file.
- Runs VEP on any variants that weren't processed by RunVep.pm (with higher memory allocation).
- Combines output with original output from RunVep.pm.


### CombineOutput.pm

- Combines VEP output for all chromosomes into single file.
- Removes temporary files.
